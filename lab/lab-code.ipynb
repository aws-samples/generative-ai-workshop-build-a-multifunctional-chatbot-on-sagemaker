{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f87dc2-e36d-4d71-856e-d1e74034bbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.0 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.22 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-common 1.2 requires psutil<7.0.0,>=5.7.3, but you have psutil 7.0.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires fsspec<=2024.10.0,>=2023.6.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires psutil~=5.9, but you have psutil 7.0.0 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --force-reinstall -q -r ./utils/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08447914-9c03-483f-83bc-223173f77db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4460e029-dc0b-4733-bdac-fedabf04c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the path to import module\n",
    "from pathlib import Path\n",
    "current_path = Path().resolve()\n",
    "current_path = current_path.parent\n",
    "if str(current_path) not in sys.path:\n",
    "    sys.path.append(str(current_path))\n",
    "# Print sys.path to verify\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53122abc-a8d2-4578-a467-c4840ac73236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('us-west-2', '010117700078')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clients\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region =  session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime') \n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837c1486-d4b7-4322-9d48-48796371813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "\n",
    "knowledge_base_name = f\"bedrock-multifunctional-chatbot-kb-{suffix}\"\n",
    "knowledge_base_description = \"Multifunctional Chatbot Knowledge Base.\"\n",
    "\n",
    "bucket_name = f'{knowledge_base_name}-{account_id}'\n",
    "intermediate_bucket_name = f'{knowledge_base_name}-intermediate-{account_id}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c288ae-e2d0-4b5a-8ae8-5588f754e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket_name = f'bedrock-kb-{suffix}-1' # replace it with your first bucket name.\n",
    "\n",
    "data_sources=[{\"type\": \"S3\", \"bucket_name\": data_bucket_name}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946d915f-a2e3-4583-b58d-208cb26d7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7220345\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.knowledge_base\n",
    "importlib.reload(utils.knowledge_base)\n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "\n",
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286d63bf-6f0d-4df5-8df6-54eb41ca050e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "Step 1 - Creating or retrieving S3 bucket(s) for Knowledge Base documents\n",
      "Creating bucket bedrock-kb-7220345-1\n",
      "========================================================================================\n",
      "Step 2 - Creating Knowledge Base Execution Role and Policies\n",
      "========================================================================================\n",
      "Step 3 - Creating OSS encryption, network and data access policies\n",
      "========================================================================================\n",
      "Step 4 - Creating OSS Collection (this step takes a couple of minutes to complete)\n",
      "Creating collection...\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Creating collection...........\n",
      "Sleeping for a minute to ensure data access rules have been enforced\n",
      "========================================================================================\n",
      "Step 5 - Creating OSS Vector Index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-17 22:09:20,975] p135 {base.py:258} INFO - PUT https://3m5htfwhxx9i1hcl2f3j.us-west-2.aoss.amazonaws.com:443/bedrock-sample-rag-index-7220345-f [status:200 request:1.245s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating index:\n",
      "{ 'acknowledged': True,\n",
      "  'index': 'bedrock-sample-rag-index-7220345-f',\n",
      "  'shards_acknowledged': True}\n",
      "========================================================================================\n",
      "Step 6 - Creating Knowledge Base\n",
      "{ 'createdAt': datetime.datetime(2025, 2, 17, 22, 10, 21, 105567, tzinfo=tzlocal()),\n",
      "  'description': 'Multifunctional Chatbot Knowledge Base.',\n",
      "  'knowledgeBaseArn': 'arn:aws:bedrock:us-west-2:010117700078:knowledge-base/EHSH1Q38GZ',\n",
      "  'knowledgeBaseConfiguration': { 'type': 'VECTOR',\n",
      "                                  'vectorKnowledgeBaseConfiguration': { 'embeddingModelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0'}},\n",
      "  'knowledgeBaseId': 'EHSH1Q38GZ',\n",
      "  'name': 'bedrock-multifunctional-chatbot-kb-7220345',\n",
      "  'roleArn': 'arn:aws:iam::010117700078:role/BedrockExecutionRoleForKnowledgeBase_7220345-f',\n",
      "  'status': 'CREATING',\n",
      "  'storageConfiguration': { 'opensearchServerlessConfiguration': { 'collectionArn': 'arn:aws:aoss:us-west-2:010117700078:collection/3m5htfwhxx9i1hcl2f3j',\n",
      "                                                                   'fieldMapping': { 'metadataField': 'text-metadata',\n",
      "                                                                                     'textField': 'text',\n",
      "                                                                                     'vectorField': 'vector'},\n",
      "                                                                   'vectorIndexName': 'bedrock-sample-rag-index-7220345-f'},\n",
      "                            'type': 'OPENSEARCH_SERVERLESS'},\n",
      "  'updatedAt': datetime.datetime(2025, 2, 17, 22, 10, 21, 105567, tzinfo=tzlocal())}\n",
      "Creating Data Sources\n",
      "{ 'createdAt': datetime.datetime(2025, 2, 17, 22, 10, 21, 791415, tzinfo=tzlocal()),\n",
      "  'dataDeletionPolicy': 'DELETE',\n",
      "  'dataSourceConfiguration': { 's3Configuration': { 'bucketArn': 'arn:aws:s3:::bedrock-kb-7220345-1'},\n",
      "                               'type': 'S3'},\n",
      "  'dataSourceId': 'LSDYTJ4PPP',\n",
      "  'description': 'Multifunctional Chatbot Knowledge Base.',\n",
      "  'knowledgeBaseId': 'EHSH1Q38GZ',\n",
      "  'name': 'EHSH1Q38GZ-s3',\n",
      "  'status': 'AVAILABLE',\n",
      "  'updatedAt': datetime.datetime(2025, 2, 17, 22, 10, 21, 791415, tzinfo=tzlocal()),\n",
      "  'vectorIngestionConfiguration': { 'chunkingConfiguration': { 'chunkingStrategy': 'FIXED_SIZE',\n",
      "                                                               'fixedSizeChunkingConfiguration': { 'maxTokens': 300,\n",
      "                                                                                                   'overlapPercentage': 20}}}}\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Creating Knowledge Base, may take a few mins.\n",
    "\n",
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data_sources,\n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = f'{suffix}-f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f2f1bf-ee90-4262-85a1-08b8746cebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_upload_squad_sample(bucket_name):\n",
    "    # Download the partial SQuAD dataset\n",
    "    url = \"https://raw.githubusercontent.com/rajpurkar/SQuAD-explorer/master/dataset/dev-v2.0.json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Select 100 as sample\n",
    "    sample_data = {\n",
    "        \"data\": data[\"data\"][:100]\n",
    "    }\n",
    "    \n",
    "    # creating the temp files locally\n",
    "    with open(\"/tmp/squad_sample.json\", \"w\") as f:\n",
    "        json.dump(sample_data, f)\n",
    "    \n",
    "    # uplaoding to s3\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.upload_file(\"/tmp/squad_sample.json\", bucket_name, \"squad_sample.json\")\n",
    "\n",
    "download_and_upload_squad_sample(data_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a0780a-2843-4f81-8c6a-fd92baca165f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job 1 started successfully\n",
      "\n",
      "{ 'dataSourceId': 'LSDYTJ4PPP',\n",
      "  'ingestionJobId': '9SUPBWDEI9',\n",
      "  'knowledgeBaseId': 'EHSH1Q38GZ',\n",
      "  'startedAt': datetime.datetime(2025, 2, 17, 22, 10, 25, 848380, tzinfo=tzlocal()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 1,\n",
      "                  'numberOfMetadataDocumentsModified': 0,\n",
      "                  'numberOfMetadataDocumentsScanned': 0,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 1},\n",
      "  'status': 'COMPLETE',\n",
      "  'updatedAt': datetime.datetime(2025, 2, 17, 22, 12, 23, 768670, tzinfo=tzlocal())}\n",
      "........................................\r"
     ]
    }
   ],
   "source": [
    "## Start the ingestion job, embedding the data sources of s3 to opensearch database.\n",
    "knowledge_base.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8168569f-da53-4909-bc68-22310ca05adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is the major context of the SQuAD dataset?\n",
      "\n",
      "Retrieved results:\n",
      "\n",
      "Result 1:\n",
      "Score: 0.37877417\n",
      "Content: {'text': ', \"id\": \"57284b904b864d19001648e2\", \"answers\": [{\"text\": \"the Main Quadrangles\", \"answer_start\": 92}, {\"text\": \"Main Quadrangles\", \"answer_start\": 96}, {\"text\": \"the Main Quadrangles\", \"answer_start\": 92}, {\"text\": \"the Main Quadrangles\", \"answer_start\": 92}], \"is_impossible\": false}, {\"question\": \"How many quadrangles does the Main Quadrangles have?\", \"id\": \"57284b904b864d19001648e3\", \"answers\": [{\"text\": \"six\", \"answer_start\": 273}, {\"text\": \"six quadrangles\", \"answer_start\": 273}, {\"text\": \"six\", \"answer_start\": 273}, {\"text\": \"six\", \"answer_start\": 273}], \"is_impossible\": false}, {\"question\": \"Who helped designed the Main Quadrangles?\"', 'type': 'TEXT'}\n",
      "\n",
      "Result 2:\n",
      "Score: 0.3762661\n",
      "Content: {'text': '\": \"explore computer networking\", \"answer_start\": 190}], \"is_impossible\": false}, {\"question\": \"What completed the triad \", \"id\": \"5726414e271a42140099d7e6\", \"answers\": [{\"text\": \"an interactive host to host connection was made between the IBM mainframe computer systems at the University of Michigan in Ann Arbor and Wayne State\", \"answer_start\": 499}, {\"text\": \"the CDC mainframe at Michigan State University in East Lansing\", \"answer_start\": 703}, {\"text\": \"1972 connections\", \"answer_start\": 683}], \"is_impossible\": false}, {\"question\": \"What set the stage for Merits role in NSFNET\", \"id\": \"5726414e271a42140099d7e7\", \"answers\": [{\"text\": \"Ethernet attached hosts, and eventually TCP/IP and additional public universities in Michigan join the network\", \"answer_start\": 1166}, {\"text\": \"the network was enhanced\", \"answer_start\": 867}, {\"text\": \"TCP/IP\", \"answer_start\": 1206}], \"is_impossible\": false}, {\"plausible_answers\": [{\"text\": \"Merit Network, Inc\", \"answer_start\": 0}], \"question\": \"State educational and economic development where helped by what?\"', 'type': 'TEXT'}\n",
      "\n",
      "Result 3:\n",
      "Score: 0.37598163\n",
      "Content: {'text': 'Although this use of the name was incorrect all these services were managed by the same people within one department of KPN contributed to the confusion.\"}, {\"qas\": [{\"question\": \"What is CSNET\", \"id\": \"5726462b708984140094c117\", \"answers\": [{\"text\": \"The Computer Science Network\", \"answer_start\": 0}, {\"text\": \"a computer network funded by the U.S.', 'type': 'TEXT'}\n",
      "\n",
      "Result 4:\n",
      "Score: 0.3758176\n",
      "Content: {'text': ', \"id\": \"5a5929d33e1742001a15cfc6\", \"answers\": [], \"is_impossible\": true}], \"context\": \"In the laboratory, stratigraphers analyze samples of stratigraphic sections that can be returned from the field, such as those from drill cores. Stratigraphers also analyze data from geophysical surveys that show the locations of stratigraphic units in the subsurface. Geophysical data and well logs can be combined to produce a better view of the subsurface, and stratigraphers often use computer programs to do this in three dimensions. Stratigraphers can then use these data to reconstruct ancient processes occurring on the surface of the Earth, interpret past environments, and locate areas for water, coal, and hydrocarbon extraction.\"}, {\"qas\": [{\"question\": \"Who analyzes rock samples from drill cores in the lab? \", \"id\": \"57268220f1498d1400e8e216\", \"answers\": [{\"text\": \"biostratigraphers\", \"answer_start\": 19}, {\"text\": \"biostratigraphers\", \"answer_start\": 19}, {\"text\": \"biostratigraphers\", \"answer_start\": 19}], \"is_impossible\": false}, {\"question\": \"Who dates rocks, precisely, within the stratigraphic section?\"', 'type': 'TEXT'}\n",
      "\n",
      "Result 5:\n",
      "Score: 0.37568116\n",
      "Content: {'text': ', \"id\": \"5a581597770dc0001aeeffe3\", \"answers\": [], \"is_impossible\": true}, {\"plausible_answers\": [{\"text\": \"the locations of stratigraphic units\", \"answer_start\": 213}], \"question\": \"What do drill cores show about water location?\", \"id\": \"5a581597770dc0001aeeffe4\", \"answers\": [], \"is_impossible\": true}, {\"plausible_answers\": [{\"text\": \"a better view of the subsurface\", \"answer_start\": 327}], \"question\": \"What can drill cores and ancient processes be combined to show?\", \"id\": \"5a581597770dc0001aeeffe5\", \"answers\": [], \"is_impossible\": true}, {\"plausible_answers\": [{\"text\": \"ancient processes occurring on the surface of the Earth\", \"answer_start\": 493}], \"question\": \"What do computers use coal to reconstruct?\", \"id\": \"5a581597770dc0001aeeffe6\", \"answers\": [], \"is_impossible\": true}, {\"plausible_answers\": [{\"text\": \"drill cores\", \"answer_start\": 132}], \"question\": \"What are taken from the laboratory into the field?\"', 'type': 'TEXT'}\n"
     ]
    }
   ],
   "source": [
    "## Testing the Knowledge Base:\n",
    "\n",
    "bedrock_agent = boto3.client('bedrock-agent-runtime')\n",
    "kb_id = knowledge_base.knowledge_base['knowledgeBaseId']\n",
    "\n",
    "def simple_kb_test(kb_id, query_text):\n",
    "    try:\n",
    "        query = {\n",
    "            \"text\": query_text \n",
    "        }\n",
    "\n",
    "        response = bedrock_agent.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery=query,  # 传入查询字典\n",
    "            retrievalConfiguration={\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\": 5,\n",
    "                } \n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nQuery: {query_text}\")\n",
    "        print(\"\\nRetrieved results:\")\n",
    "        for i, result in enumerate(response['retrievalResults'], 1):\n",
    "            print(f\"\\nResult {i}:\")\n",
    "            print(f\"Score: {result['score']}\")\n",
    "            print(f\"Content: {result['content']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "test_query = \"What is the major context of the SQuAD dataset?\"\n",
    "\n",
    "simple_kb_test(kb_id, test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac456d68-df14-4519-8599-cf1febc77b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: ACTIVE\n",
      "Inference profile created successfully: arn:aws:bedrock:us-west-2:010117700078:application-inference-profile/732bbsotu6s5\n"
     ]
    }
   ],
   "source": [
    "## Creating Inference Profile for Amazon Nova Pro model.\n",
    "\n",
    "nova_pro_profile_name = f'bedrock-kb-nova-pro-profile-{suffix}' \n",
    "profile_arn = knowledge_base.create_nova_inference_profile(nova_pro_profile_name, throughput=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4978f2-dbf8-4df7-8cd9-226d840a03e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'deepseek-llm-r1-distill-qwen-1-5b' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "[2025-02-17 22:13:08,069] p135 {cache.py:625} WARNING - Using model 'deepseek-llm-r1-distill-qwen-1-5b' with wildcard version identifier '*'. You can pin to version '1.0.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "[2025-02-17 22:13:08,118] p135 {session.py:4094} INFO - Creating model with name: deepseek-llm-r1-distill-qwen-1-5b-2025-02-17-22-13-08-116\n",
      "[2025-02-17 22:13:08,911] p135 {session.py:5889} INFO - Creating endpoint-config with name deepseek-llm-r1-distill-qwen-1-5b-2025-02-17-22-13-08-117\n",
      "[2025-02-17 22:13:09,247] p135 {session.py:4711} INFO - Creating endpoint with name deepseek-llm-r1-distill-qwen-1-5b-2025-02-17-22-13-08-117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "## Creating Deepseek model with Sagemaker JumpStart\n",
    "\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model_id = \"deepseek-llm-r1-distill-qwen-1-5b\"\n",
    "my_model = JumpStartModel(model_id=model_id, instance_type='ml.g5.2xlarge')\n",
    "\n",
    "predictor = my_model.deploy()\n",
    "\n",
    "deepseek_sagemaker_endpoint = predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d04dfb-bde7-4e46-accd-12d6131fc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing configurations into a config file, then access by the  Streamlit APP\n",
    "\n",
    "config = {\n",
    "    \"kb_id\": kb_id,\n",
    "    \"nova_pro_profile_arn\": profile_arn,\n",
    "    \"nova_pro_model_id\": \"amazon.nova-pro-v1:0\",\n",
    "    \"sagemaker_endpoint\": deepseek_sagemaker_endpoint,\n",
    "    \"sagemaker_ep_arn\" : f\"arn:aws:sagemaker:{region}:{account_id}:endpoint/{deepseek_sagemaker_endpoint}\",\n",
    "    \"region_name\": region\n",
    "}\n",
    "\n",
    "with open('utils/tmp_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfea279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=============================== All resources have been completed, please starting your demo ==============================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec68277-54b8-41a6-8690-af030a71dda0",
   "metadata": {},
   "source": [
    "#### Start a Terminal Session on Jupyterlab, then execute the below command:\n",
    "\n",
    "```bash\n",
    "pip install streamlit\n",
    "\n",
    "streamlit run demo-dev/app.py \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc4ae8-2a85-4e8d-8453-9a5ed922b90e",
   "metadata": {},
   "source": [
    "#### To access the Streamlit Web Application via:\n",
    "\n",
    "1. Copy & paste the URL of the Sagemaker Studio Jupyterlab web URL, eg:\n",
    "\n",
    "https://xxxxxxxxxxxxx.studio.us-west-2.sagemaker.aws/jupyterlab/default/lab/.../lab-code.ipynb\n",
    "\n",
    "\n",
    "2. Update the url as below format, and access the url via a new browser tab:\n",
    "\n",
    "https://xxxxxxxxxxxxx.studio.us-west-2.sagemaker.aws/jupyterlab/default/proxy/8501/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c01f6e3-748e-4e28-9a5c-c3403f69bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================Knowledge base with fixed chunking==============================\n",
      "\n",
      "File utils/tmp_config.json has been deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "## Clean up\n",
    "\n",
    "\n",
    "# print(\"===============================Starting Clean up==============================\\n\")\n",
    "# predictor.delete_predictor()\n",
    "# knowledge_base.delete_kb(delete_s3_bucket=True)\n",
    "\n",
    "# file_path = 'utils/tmp_config.json'\n",
    "# if os.path.exists(file_path):\n",
    "#     os.remove(file_path)\n",
    "#     print(f\"File {file_path} has been deleted successfully.\")\n",
    "# else:\n",
    "#     print(f\"File {file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735201cf-054f-4d0d-8d3e-7b6b743feb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
